# 0x08-h Performance Monitoring & Observability

<h3>
  <a href="#-english">ğŸ‡ºğŸ‡¸ English</a>
  &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;
  <a href="#-chinese">ğŸ‡¨ğŸ‡³ ä¸­æ–‡</a>
</h3>

<div id="-english"></div>

## ğŸ‡ºğŸ‡¸ English

> **ğŸ“¦ Code Changes**: [View Diff](https://github.com/gjwang/zero_x_infinity/compare/v0.8-f-ring-buffer-pipeline...v0.8-h-performance-monitoring) | [Key File: pipeline_services.rs](https://github.com/gjwang/zero_x_infinity/blob/main/src/pipeline_services.rs)

"If you can't measure it, you can't improve it." This chapter focuses on introducing production-grade performance monitoring and observability for our multi-threaded pipeline.

## Monitoring Dimensions

### 1. Latency Metrics
In HFT, averages are misleading. We care about **Tail Latency**.
- **P50 (Median)**: General performance.
- **P99 / P99.9**: Stability in extreme cases.
- **Max**: Jitter, GC, or system calls.

### 2. Throughput
- **Orders/sec**: Processing capacity.
- **Trades/sec**: Matching capacity.

### 3. Queue Depth & Backpressure
Monitoring Ring Buffer occupancy reveals downstream bottlenecks and jitter.

### 4. Architectural Breakdown
Knowing where time is spent (Pre-Trade vs Matching vs Settlement).

---

## Test Execution

**Dataset**: 1.3M orders (30% cancel) from `fixtures/test_with_cancel_highbal/`.

**Single-Thread Run**:
```bash
cargo run --release -- --pipeline --input fixtures/test_with_cancel_highbal
```

**Multi-Thread Run**:
```bash
cargo run --release -- --pipeline-mt --input fixtures/test_with_cancel_highbal
```

**Compare Script**:
```bash
./scripts/test_pipeline_compare.sh highbal
```

---

## Analysis Results (1.3M Dataset)

### 1. Single-Thread Pipeline
*   **Throughput**: 210,000 orders/sec (P50 Latency: 1.25 Âµs)
*   **Breakdown**:
    *   Matching Engine: **91.5%** (The bottleneck)
    *   UBSCore Lock: 5.6%
    *   Persistence: 2.7%

### 2. Multi-Thread Pipeline (After Service Refactor)
*   **Throughput**: ~64,450 orders/sec
*   **E2E Latency (P50)**: ~113 ms
*   **E2E Latency (P99)**: ~188 ms

### Conclusion
1.  **Parallelism Works**: Total task CPU time (~34s) > Wall time (17.5s).
2.  **Bottleneck**: **Matching Engine** remains the serial bottleneck (~52k ops/s limit).
3.  **Latency Cost**: Multi-threading introduces significant message passing latency (Âµs â†’ ms).

---

## Logging & Observability

We introduced a production-grade asynchronous logging system using `tracing`.

### 1. Non-blocking I/O
Using `tracing-appender` with a dedicated worker thread and memory buffer to prevent I/O blocking.

### 2. Environment-driven Config
*   **Dev**: Detailed, human-readable.
*   **Prod**: JSON format, high-frequency tracing disabled (`0XINFI=off`).

### 3. Standardized Targets
All pipeline logs use the **`0XINFI`** namespace (e.g., `0XINFI::ME`, `0XINFI::UBSC`) for precise filtering.

---

## Intent-Based Design: From Functions to Services

> "Good architecture is not designed upfront, but evolved through refactoring."

We refactored tightly coupled `spawn_*` functions into decoupled **Service Structs**.

### Problem: Coupled Functions

```rust
// âŒ Business logic buried in thread spawning
fn spawn_me_stage(...) -> JoinHandle<OrderBook> {
    thread::spawn(move || {
        // Logic locked inside closure
    })
}
```

*   **Untestable**: Cannot unit test logic without spawning threads.
*   **Not Reusable**: Cannot be used in single-thread mode.

### Solution: Service Structs

```rust
// âœ… Intent is clear and decoupled
pub struct MatchingService {
    book: OrderBook,
    // ...
}

impl MatchingService {
    pub fn run(&mut self, shutdown: &ShutdownSignal) { ... }
}
```

### Benefits
*   **Testability**: Services can be instantiated and tested in isolation.
*   **Reusability**: Core logic is decoupled from threading model.
*   **Clarity**: Code expresses "what" (Service), not just "how" (Thread).

<br>
<div align="right"><a href="#-english">â†‘ Back to Top</a></div>
<br>

---

<div id="-chinese"></div>

## ğŸ‡¨ğŸ‡³ ä¸­æ–‡

> **ğŸ“¦ ä»£ç å˜æ›´**: [æŸ¥çœ‹ Diff](https://github.com/gjwang/zero_x_infinity/compare/v0.8-f-ring-buffer-pipeline...v0.8-h-performance-monitoring) | [å…³é”®æ–‡ä»¶: pipeline_services.rs](https://github.com/gjwang/zero_x_infinity/blob/main/src/pipeline_services.rs)

åœ¨æ„å»ºé«˜æ€§èƒ½ä½å»¶è¿Ÿäº¤æ˜“ç³»ç»Ÿæ—¶ï¼Œ"å¦‚æœä½ æ— æ³•æµ‹é‡å®ƒï¼Œä½ å°±æ— æ³•ä¼˜åŒ–å®ƒ"ã€‚æœ¬ç« é‡ç‚¹åœ¨äºä¸ºæˆ‘ä»¬çš„å¤šçº¿ç¨‹ Pipeline å¼•å…¥ç”Ÿäº§çº§çš„æ€§èƒ½ç›‘æ§å’Œå»¶è¿ŸæŒ‡æ ‡åˆ†æã€‚

## ç›‘æ§ç»´åº¦

### 1. å»¶è¿ŸæŒ‡æ ‡ (Latency Metrics)
å¯¹äº HFT ç³»ç»Ÿï¼Œå¹³å‡å»¶è¿Ÿå¾€å¾€æ˜¯è¯¯å¯¼æ€§çš„ï¼Œæˆ‘ä»¬æ›´å…³å¿ƒ**é•¿å°¾å»¶è¿Ÿ (Tail Latency)**ã€‚
- **P50 (Median)**: ä¸­ä½æ•°å»¶è¿Ÿï¼Œåæ˜ å¹³å‡æ°´å¹³ã€‚
- **P99 / P99.9**: é•¿å°¾å»¶è¿Ÿï¼Œåæ˜ ç³»ç»Ÿåœ¨æç«¯æƒ…å†µä¸‹çš„ç¨³å®šæ€§ã€‚
- **Max**: å³°å€¼å»¶è¿Ÿï¼Œé€šå¸¸ç”±ç³»ç»ŸæŠ–åŠ¨ (Jitter) æˆ– GC/ç³»ç»Ÿè°ƒç”¨å¼•èµ·ã€‚

### 2. ååé‡ (Throughput)
- **Orders/sec**: æ¯ç§’å¤„ç†è®¢å•æ•°ã€‚
- **Trades/sec**: æ¯ç§’æ’®åˆæˆäº¤æ•°ã€‚

### 3. é˜Ÿåˆ—æ·±åº¦ä¸èƒŒå‹ (Queue Depth & Backpressure)
ç›‘æ§ Ring Buffer çš„å ç”¨æƒ…å†µï¼Œè¯†åˆ«ä¸‹æ¸¸ç“¶é¢ˆã€‚

### 4. æ¶æ„å†…éƒ¨é˜¶æ®µè€—æ—¶ (Architectural Breakdown)
æ¸…æ™°åœ°çŸ¥é“æ—¶é—´èŠ±åœ¨äº†å“ªé‡Œï¼šPre-Trade / Matching / Settlement / Loggingã€‚

## æµ‹è¯•æ‰§è¡Œæ–¹æ³•

**æ•°æ®é›†**: 130 ä¸‡è®¢å•ï¼ˆå« 30% æ’¤å•ï¼‰ `fixtures/test_with_cancel_highbal/`ã€‚

**è¿è¡Œå•çº¿ç¨‹**:
```bash
cargo run --release -- --pipeline --input fixtures/test_with_cancel_highbal
```

**è¿è¡Œå¤šçº¿ç¨‹**:
```bash
cargo run --release -- --pipeline-mt --input fixtures/test_with_cancel_highbal
```

**å¯¹æ¯”è„šæœ¬**:
```bash
./scripts/test_pipeline_compare.sh highbal
```

## æ‰§è¡Œç»“æœä¸åˆ†æ (1.3M æ•°æ®é›†)

### 1. å•çº¿ç¨‹æµæ°´çº¿
*   **æ€§èƒ½**: 210,000 orders/sec (P50: 1.25 Âµs)
*   **ç“¶é¢ˆ**: **Matching Engine** è€—æ—¶ 91.5%ï¼Œæ˜¯æœ€å¤§ç“¶é¢ˆã€‚

### 2. å¤šçº¿ç¨‹æµæ°´çº¿ (é‡æ„å)
*   **ååé‡**: ~64,450 orders/sec
*   **ç«¯åˆ°ç«¯å»¶è¿Ÿ (P50)**: ~113 ms
*   **ç«¯åˆ°ç«¯å»¶è¿Ÿ (P99)**: ~188 ms

### ç»“è®º
1.  **å¹¶è¡Œæœ‰æ•ˆ**: CPU æ€»è€—æ—¶è¿œå¤§äºæ‰§è¡Œæ—¶é—´ã€‚
2.  **ç“¶é¢ˆ**: **Matching Engine** ä¾ç„¶æ˜¯æœ€å¤§çš„ä¸²è¡Œç“¶é¢ˆ (ååä¸Šé™ ~52k)ã€‚
3.  **å»¶è¿Ÿ**: å¤šçº¿ç¨‹å¼•å…¥çš„æ¶ˆæ¯ä¼ é€’å¼€é”€å¯¼è‡´ç«¯åˆ°ç«¯å»¶è¿Ÿä»å¾®ç§’çº§é€€åŒ–åˆ°æ¯«ç§’çº§ã€‚

## æ—¥å¿—ä¸å¯è§‚æµ‹æ€§

å¼•å…¥åŸºäº `tracing` çš„ç”Ÿäº§çº§å¼‚æ­¥æ—¥å¿—ä½“ç³»ã€‚

### 1. å¼‚æ­¥éé˜»å¡æ¶æ„
ä½¿ç”¨ `tracing-appender` ç‹¬ç«‹çº¿ç¨‹å†™å…¥æ—¥å¿—ï¼Œä¸é˜»å¡ä¸šåŠ¡çº¿ç¨‹ã€‚

### 2. ç¯å¢ƒé©±åŠ¨é…ç½®
Dev å¼€å¯è¯¦ç»†æ—¥å¿—ï¼ŒProd ä½¿ç”¨ JSON å¹¶å…³é—­é«˜é¢‘è¿½è¸ªã€‚

### 3. æ ‡å‡†åŒ–æ—¥å¿—ç›®æ ‡
ä½¿ç”¨ **`0XINFI`** å‘½åç©ºé—´ (å¦‚ `0XINFI::ME`) å®ç°ç²¾ç»†è¿‡æ»¤ã€‚

## æ„å›¾ç¼–ç ï¼šä»å‡½æ•°åˆ°æœåŠ¡

> "å¥½çš„æ¶æ„ä¸æ˜¯ä¸€å¼€å§‹å°±è®¾è®¡å‡ºæ¥çš„ï¼Œè€Œæ˜¯é€šè¿‡ä¸æ–­é‡æ„æ¼”è¿›å‡ºæ¥çš„ã€‚"

æˆ‘ä»¬å°†ç´§è€¦åˆçš„ `spawn_*` å‡½æ•°é‡æ„ä¸ºè§£è€¦çš„ **Service ç»“æ„ä½“**ã€‚

### é—®é¢˜ï¼šç´§è€¦åˆ

```rust
// âŒ ä¸šåŠ¡é€»è¾‘åŸ‹åœ¨çº¿ç¨‹åˆ›å»ºä¸­
fn spawn_me_stage(...) {
    thread::spawn(move || { ... })
}
```
æ— æ³•å•å…ƒæµ‹è¯•ï¼Œæ— æ³•å¤ç”¨ã€‚

### è§£å†³æ–¹æ¡ˆï¼šService ç»“æ„ä½“

```rust
// âœ… æ„å›¾æ¸…æ™°ï¼Œè§£è€¦
pub struct MatchingService { ... }

impl MatchingService {
    pub fn run(&mut self, shutdown: &ShutdownSignal) { ... }
}
```

### æ”¶ç›Š
*   **å¯æµ‹è¯•æ€§**: æœåŠ¡å¯ç‹¬ç«‹å®ä¾‹åŒ–æµ‹è¯•ã€‚
*   **å¯å¤ç”¨æ€§**: æ ¸å¿ƒé€»è¾‘ä¸çº¿ç¨‹æ¨¡å‹è§£è€¦ã€‚
*   **æ¸…æ™°åº¦**: ä»£ç è¡¨è¾¾"åšä»€ä¹ˆ" (Service)ï¼Œè€Œé"æ€ä¹ˆåš" (Thread)ã€‚
